{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 2. Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание методического пособия:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Способы создания нейросетей</li>\n",
    "<li>Что такое Keras</li>\n",
    "<li>Основы синтаксиса</li>\n",
    "<li>Простая нейросеть на Keras</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Способы создания нейросетей\n",
    "\n",
    "Нейросети это математические модели. Программирую на любом языке можно решать задачи связанные с математикой. Однако встает вопрос какой язык подойдет для этого больше? Не считая учебных нейросетей, нейросети как правило работают с большим количеством данных. Поэтому, чтобы обучение нейросетей происходило с приемлимой скоростью нужно использовать быстрый язык. Например Си. Но так как язык Си это язык с низким уровнем абстракции то программировать и модифицировать на нем нейросети было бы крайне затруднительно. \n",
    "\n",
    "Хорошо может подойти для этих целей язык Python. Так как он с одной стороны имеет высокий уровень абстракции с другой стороны операции с массивами данных могут сделать его библиотеки написанные на Си. Таким способом мы пользовались на первых 2 уроках. Однако если писать нейросети таким образом то будет много повторяющегося кода поскольку архитектуры нейросетей остаются одинаковыми и зачастую у них только меняются параметры. Кроме этого нам может понадобиться хорошо знать архитектуры самых разных нейронных сетей чтобы реализовать их вручную. Работа таким образом затруднительна для людей не имеющих достаточной подготовки, а для имеющих может быть нааборот рутиной.\n",
    "\n",
    "Существуют фреймворки для созданий нейронных сетей. Они являются, пожалуй основным рабочим способом создания нейронных сетей. Вот их неполный перечень:\n",
    "\n",
    "1. TensorFlow\n",
    "2. PyTorch\n",
    "3. Keras\n",
    "4. Microsoft Cognitive Toolkit (CNTK)\n",
    "5. Caffe\n",
    "6. Apache MXNet\n",
    "\n",
    "Упрощение создания нейронных сетей не заканчивается на этих фрейворках. Существуют инструменты которые позволяют создавать нейронные сети без навыков программирования, строя нейросети графически. Примеры: Neural Designer, Deep Learning Studio.\n",
    "\n",
    "Но и на этом не заканчиваются способы создания нейросетей. Существуют инструменты самостоятельно создающие нейронные сети. Это так называемые AutoML инструменты. Вот примеры популярных из них:\n",
    "1. MLBox\n",
    "2. TPOT\n",
    "3. Autokeras\n",
    "\n",
    "Как вы возможно заметили что все эти инструменты отранжированы походы изложения в порядке возрастания уровня абстракции. Соответсвенно говоря о плюсах минусах того или иного инструмента мы должны понимать в принципе плюсы минусы повышения уровня абстракции. Чем он выше тем меньше производительность и тем меньше его гибкость и набоорот.\n",
    "\n",
    "Как уже было сказано наиболее востребованных в рабочих целях является тот уровень абстракции, который дают фреймворки. Будем изучать дальше и пользовать ими. Остается сделать выбор среди них. Самый популярный фреймворк для создания нейросетей TensorFlow. Самый популярный для обучения - Keras. На этом уроке мы изучим с вами Keras, а на следующим TensorFlow. Также стоит отметить, что эти фреймворки взаимосвязаны - Keras как правило работает поверх TensorFlow, а сам TensorFlow позволяет пользовать средствами Keras при необходимости.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такое Keras\n",
    "\n",
    "Keras появился относительно недавно - в 2015 г. Но за это время стал одним из самых популярных фреймоворков для создания нейросетей и фактически стандартом для использования его начинающими.\n",
    "\n",
    "В чем причина его популярности? Keras позволяет создовать на высоком уровне абстракции. Т.е. на не нужно вручную реализовать с помощью математикаподобного кода те или иные элементы нейронной сети. Мы можем оперировать слоями, количеством нейронов в них, выбором функции активации и т.д. В тоже время keras содержит инструментарий для всего того, что может понадобиться для работы - например ряд встроенных датасетов, возможность обрабатывать изображения.\n",
    "\n",
    "В техническом плане Keras это оболочка над инструментами меньшей степени абстракции. На выбор он может работать поверх TensorFlow, Microsoft Cognitive Toolkit, R, Theano, PlaidML.\n",
    "\n",
    "Keras пользуется также на соревнованиях Kaggle.\n",
    "\n",
    "Однако стоит отметить, что в реальных проектах чаще используется TensorFlow, который мы будем изучать в след. уроках.\n",
    "\n",
    "Keras как и любой высокобастрактный инструмент имеет изъяны в качестве меньшей гибкостью и производительснотью чем тот же tensorflow.\n",
    "\n",
    "Стоит также отметить, что Google официально поддерживает Keras, его автор François Chollet, является сотрудником Google. TensorFlow сам в свою очередь позволяет использовать возможности Keras, т.е. в нем заложена возможность переходить на более высокой уровень абстракции.\n",
    "\n",
    "В данном уроке мы с вами рассмотрим пример обучения нейронной сети с помощью Keras. Но прежде давайте посмотрим на основы синтаксиса Keras и стандартные задачи, которые нужно выполнить при обучении нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы синтаксиса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Установка и работа с данными**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала необходимо установить keras. Надо полагать вы хорошо знакомы с командой pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo python3 pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем получить датасет mnist и проанализировать его содержимое.\n",
    "Это еще не будет синтаксис Keras, но это часто встречающаяся задача. Не обращайте внимание на предупреждения от TensorFlow. Их часто бывает много и их можно подавить при необходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "    import numpy as np\n",
    "    import mnist\n",
    "    import keras\n",
    "    import tensorflow\n",
    "\n",
    "    # The first time you run this might be a bit slow, since the\n",
    "    # mnist package has to download and cache the data.\n",
    "    train_images = mnist.train_images()\n",
    "    train_labels = mnist.train_labels()\n",
    "\n",
    "    print(train_images.shape) # (60000, 28, 28)\n",
    "    print(train_labels.shape) # (60000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что в данном случае мы смогли с вами узнать? Что тренировочный датасет mnist состоит из 60000 изображений 28 на 28 пикселей. Такие небольшие датасеты с маленькими изображениями встретятся вам и в других учебных датасетах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нам нужно делать теперь? Если скаченный нами датасет не имеет разделения на тренировочный и тестовый то поделить их. В нашем случае наш тренировочный датасет состоит из 60 000 изображений и тестовый из 10 000 и они поделены по умолчанию.\n",
    "\n",
    "Нам теперь нужно конверитировать значения пикселей из вида от 1 до 255 в набор значений от -0.5 до 0.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import numpy as np\n",
    "    import mnist\n",
    "\n",
    "    train_images = mnist.train_images()\n",
    "    train_labels = mnist.train_labels()\n",
    "    test_images = mnist.test_images()\n",
    "    test_labels = mnist.test_labels()\n",
    "\n",
    "    # Normalize the images.\n",
    "    train_images = (train_images / 255) - 0.5\n",
    "    test_images = (test_images / 255) - 0.5\n",
    "\n",
    "    # Flatten the images.\n",
    "    train_images = train_images.reshape((-1, 784))\n",
    "    test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "    print(train_images.shape) # (60000, 784)\n",
    "    print(test_images.shape)  # (10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После первичной подготовки данных дальше как правило следует создание модели нейронной сети, которая будет учиться на этих данных.\n",
    "\n",
    "Ниже типичный код учебной нейросети - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся с теми командами, которые нам встетились в этом коде.\n",
    "\n",
    "Sequential - позволяет создать нейросети где слои имеют форму стека. Сигнал в них передается от одного слоя к другому. В противовес этой разновидности есть нейросети где сигнал может не сразу передаваться в следующий слой а попадать в цикл. Такие нейросети мы разберем в следующих уроках.\n",
    "\n",
    "Dense - позволяет каждому нейронну быть связанному с другим нейронном. В противовес этом может быть необходимость не делать так много связей. Неполносвязнные архитектуры мы также разберем на этом курсе, они основа компьютерного зрения.\n",
    "\n",
    "Цифры 12, 8, 1 обозначают количество нейронов в каждом конкретном слое\n",
    "\n",
    "Activation - позволяет определить формулу по которой будет активироваться нейрон."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Компиляция модели**\n",
    "\n",
    "На этапе компиляции модель с заданными параметрами ранее создается. Вот типичный учебный пример:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # создание keras модели\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако на этой стадии мы должны сделать еще некоторые настройки нейронной сети. Разберем команды из кода выше.\n",
    "\n",
    "loss - позволяет задать формулы по которой будет определяться степень ошибки нейронной сети.\n",
    "\n",
    "optimizer - позволяет задать алгоритм, который будет осуществлять изменения весов по всей нейронной сети (backpropagation)\n",
    "\n",
    "metrics - позволяет опредилить кретирии по которым будет оцениваться степень обученности нейросети.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Передача данных для обучения нейросети**\n",
    "\n",
    "После того как нейросеть создана можно передавать ей данные для обучения. Ниже типичный пример кода для этого.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # передача обучающего датасета keras модели\n",
    "    model.fit(X, y, epochs=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберем команды из этого примера.\n",
    "X, y - содержат все обучающие данные\n",
    "epochs - определяет сколько раз через нейросеть должен пройти весь набор данных\n",
    "bath_size - определяет количество обучающих примеров передающихся нейросети на каждой итерации обучения.\n",
    "verbose - позволяет определять информацию, котору вы видете во время обучения нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка обученности нейронной сети**\n",
    "\n",
    "Следующей стадией может быть проверка обученности нейронной сети. Команда Keras для этих целей - \n",
    "\n",
    "    results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "    \n",
    "В данном случае мы просто указываем какую модель на каких данных мы хотим проверить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запуск нейронной сети для выполнения работы**\n",
    "\n",
    "На этой стадии мы можем попробовать запустить нейронную сеть на данных которые мы хотели бы чтобы она оценила. Осуществить распознования объекта на фотографии например.\n",
    "Вот код для этих целей - \n",
    "\n",
    "    predictions = model.predict(x_test[:3])\n",
    "    \n",
    "В качестве аргумента здесь указывается массив даныхх содержащих, например фотографию в виде массива чисел.    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы с вами рассмотрели основные стадии процесса обучения нейросети и команды Keras, для этого. Безусловно здесь приведен далеко неполный перечень возможностей Keras. У Keras есть также возможность сохранять созданную нейросеть, запускать уже имеющиюся, различные средства для создания нейросетей разных архитектур и другое. С чем то из арсенала Keras мы с вами познакомимся по ходу курса, а с остальным вы можете познакомиться на сайте Keras в разделе документация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простая нейросеть на Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попрубуем сделать нейросеть на Keras использую полученные выше знания. Попробуем обучить нейросеть различать рукописные цифры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1715/1715 [==============================] - 2s 904us/step - loss: 0.2801 - accuracy: 0.9176\n",
      "Epoch 2/10\n",
      "1715/1715 [==============================] - 2s 893us/step - loss: 0.1286 - accuracy: 0.9622\n",
      "Epoch 3/10\n",
      "1715/1715 [==============================] - 2s 902us/step - loss: 0.0971 - accuracy: 0.9711\n",
      "Epoch 4/10\n",
      "1715/1715 [==============================] - 2s 903us/step - loss: 0.0808 - accuracy: 0.9761\n",
      "Epoch 5/10\n",
      "1715/1715 [==============================] - 2s 899us/step - loss: 0.0685 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "1715/1715 [==============================] - 2s 910us/step - loss: 0.0617 - accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "1715/1715 [==============================] - 2s 900us/step - loss: 0.0535 - accuracy: 0.9841\n",
      "Epoch 8/10\n",
      "1715/1715 [==============================] - 2s 923us/step - loss: 0.0489 - accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "1715/1715 [==============================] - 2s 922us/step - loss: 0.0449 - accuracy: 0.9877\n",
      "Epoch 10/10\n",
      "1715/1715 [==============================] - 2s 926us/step - loss: 0.0408 - accuracy: 0.9882\n",
      "313/313 [==============================] - 0s 586us/step - loss: 0.1099 - accuracy: 0.9764\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb8eda03a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# The full neural network code!\n",
    "###############################\n",
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.1\n",
    "test_images = (test_images / 255) - 0.1\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=10,\n",
    "  batch_size=35,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('model.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте обучить, нейронную сеть на Keras(рассмотренную на уроке) на датасете MNIST с другими параметрами. \n",
    "        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?</li>\n",
    "    <li>Поработайте с документацией Keras. Попробуйте найти полезные команды Keras неразобранные на уроке.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. As I understand in the following formula:\n",
    "    _____________________\n",
    "    Normalize the images.\n",
    "    \n",
    "    train_images = (train_images / 255) - 0.5\n",
    "    test_images = (test_images / 255) - 0.5\n",
    "    _____________________\n",
    "\n",
    "    0.5 is a bias. So I changed this number from 0.5 to 0.1 (the result is +1% in final accuracy)\n",
    "    \n",
    "    Sergey I will appriciate if you provide the explanation how this change affected the result that much. According to my expectation thare should be no change because of this change.\n",
    "    \n",
    "    2. increased the number of epochs from 5 to 10 (the result is +0.5% in final accuracy)\n",
    "    3. There is no reason to touch the batch_size setting because in our case it doesnt make sense\n",
    "    4. Chenged optimizer to 'rmsprop' which added another 0.2%\n",
    "    \n",
    "    So in our case our top performers are point 1 & 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: Make a model where we fit only last layer (other weights are taken from the pretrained model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1715/1715 [==============================] - 2s 930us/step - loss: 0.0381 - accuracy: 0.9893\n",
      "Epoch 2/10\n",
      "1715/1715 [==============================] - 2s 921us/step - loss: 0.0339 - accuracy: 0.9901\n",
      "Epoch 3/10\n",
      "1715/1715 [==============================] - 2s 903us/step - loss: 0.0318 - accuracy: 0.9910\n",
      "Epoch 4/10\n",
      "1715/1715 [==============================] - 2s 935us/step - loss: 0.0304 - accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "1715/1715 [==============================] - 2s 922us/step - loss: 0.0266 - accuracy: 0.9921\n",
      "Epoch 6/10\n",
      "1715/1715 [==============================] - 2s 925us/step - loss: 0.0255 - accuracy: 0.9930\n",
      "Epoch 7/10\n",
      "1715/1715 [==============================] - 2s 912us/step - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 8/10\n",
      "1715/1715 [==============================] - 2s 936us/step - loss: 0.0226 - accuracy: 0.9937\n",
      "Epoch 9/10\n",
      "1715/1715 [==============================] - 2s 933us/step - loss: 0.0206 - accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "1715/1715 [==============================] - 2s 916us/step - loss: 0.0208 - accuracy: 0.9942\n",
      "313/313 [==============================] - 0s 589us/step - loss: 0.2282 - accuracy: 0.9717\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb8e9919b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# The full neural network code!\n",
    "###############################\n",
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.1\n",
    "test_images = (test_images / 255) - 0.1\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model2 = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Presumably you would want to first load pre-trained weights.\n",
    "model2.load_weights('model.h5')\n",
    "\n",
    "\n",
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "# Compile the model.\n",
    "model2.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model2.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=10,\n",
    "  batch_size=35,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model2.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model2.save_weights('model2.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('model.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions2 = model2.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions2, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>https://keras.io/</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://keras.io/</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Википедия</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
